{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1229626/3734358892.py:5: DtypeWarning: Columns (19,20,21,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  usdf = pd.read_csv(os.path.join(preprocessed_folder_path, 'us.csv'))\n",
      "/tmp/ipykernel_1229626/3734358892.py:6: DtypeWarning: Columns (19,20,21,23,31,33,34,35,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  jpdf = pd.read_csv(os.path.join(preprocessed_folder_path, 'jp.csv'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "preprocessing_folder_path = '/home/local/PSYCH-ADS/xuqian_chen/Github/twitter_entropy/code/preprocessing/'\n",
    "preprocessed_folder_path = '/home/local/PSYCH-ADS/xuqian_chen/Github/twitter_entropy/data/preprocessed/'\n",
    "usdf = pd.read_csv(os.path.join(preprocessed_folder_path, 'us.csv'))\n",
    "jpdf = pd.read_csv(os.path.join(preprocessed_folder_path, 'jp.csv'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entropy calculation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_en_nrc_emotion_lexicon(txt_path):\n",
    "    with open(txt_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    data = [line.strip().split('\\t') for line in lines]\n",
    "    df = pd.DataFrame(data, columns=[\"word\", \"emotion\", \"value\"])\n",
    "    df[\"value\"] = df[\"value\"].astype(int)\n",
    "    \n",
    "    df = df[df[\"value\"] == 1]\n",
    "    emotion_dict = {emotion: set(df[df[\"emotion\"] == emotion][\"word\"]) for emotion in df[\"emotion\"].unique()}\n",
    "    \n",
    "    return emotion_dict\n",
    "\n",
    "# path_to_english_nrc = os.path.join(preprocessing_folder_path, 'NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')\n",
    "path_to_english_nrc = '/home/local/PSYCH-ADS/xuqian_chen/Github/twitter_entropy/data/preprocessing/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "english_nrc_emotion_dict = load_en_nrc_emotion_lexicon(path_to_english_nrc)\n",
    "\n",
    "\n",
    "def load_jp_nrc_emotion_lexicon(file_path):\n",
    "    emotion_dict = {\"anger\": set(), \"anticipation\": set(), \"disgust\": set(), \"fear\": set(), \"joy\": set(),\n",
    "                    \"negative\": set(), \"positive\": set(), \"sadness\": set(), \"surprise\": set(), \"trust\": set()}\n",
    "\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        next(f)  # Skip the header line\n",
    "        for line in f:\n",
    "            split_line = line.strip().split(\"\\t\")\n",
    "            japanese_word = split_line[-1]\n",
    "            emotions = [emotion for emotion, value in zip(emotion_dict.keys(), split_line[1:-1]) if int(value) == 1]\n",
    "\n",
    "            for emotion in emotions:\n",
    "                emotion_dict[emotion].add(japanese_word.lower())\n",
    "\n",
    "    return emotion_dict\n",
    "\n",
    "# path_to_japanese_nrc = os.path.join(preprocessing_folder_path, 'Japanese-NRC-EmoLex.txt')\n",
    "path_to_japanese_nrc = '/home/local/PSYCH-ADS/xuqian_chen/Github/twitter_entropy/data/preprocessing/Japanese-NRC-EmoLex.txt'\n",
    "japanese_nrc_emotion_dict = load_jp_nrc_emotion_lexicon(path_to_japanese_nrc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT IN USE: roberta senetiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 22:26:10.963327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-20 22:26:10.963347: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion loadings: [0.9440009593963623]\n",
      "Emotion entropy: 1.292481250360578\n",
      "Emotion loadings: [0.9440009593963623]\n",
      "Emotion entropy: -0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "def get_emotion_loadings(tweet_text):\n",
    "    model_name = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    emotion_classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    result = emotion_classifier(tweet_text)\n",
    "\n",
    "    # Extract emotion probabilities\n",
    "    emotion_probabilities = [entry[\"score\"] for entry in result]\n",
    "    return emotion_probabilities\n",
    "\n",
    "# Example usage\n",
    "tweet_text = \"I love this new phone! It's amazing.\"\n",
    "emotion_loadings = get_emotion_loadings(tweet_text)\n",
    "print(\"Emotion loadings:\", emotion_loadings)\n",
    "\n",
    "def emotion_entropy(post_emotions, threshold=0.5):\n",
    "    binary_emotions = [1 if emotion >= threshold else 0 for emotion in post_emotions]\n",
    "    probabilities = [emotion_count / len(post_emotions) for emotion_count in binary_emotions]\n",
    "    \n",
    "    entropy = -np.sum([p * np.log2(p) if p > 0 else 0 for p in probabilities])\n",
    "    return entropy\n",
    "\n",
    "# Example usage\n",
    "post_emotions = [0.7, 0.2, 0.8, 0.4, 0.6, 0.1]\n",
    "entropy = emotion_entropy(post_emotions)\n",
    "print(\"Emotion entropy:\", entropy)\n",
    "\n",
    "tweet_text = \"I love this new phone! It's amazing.\"\n",
    "emotion_loadings = get_emotion_loadings(tweet_text)\n",
    "entropy = emotion_entropy(emotion_loadings)\n",
    "print(\"Emotion loadings:\", emotion_loadings)\n",
    "print(\"Emotion entropy:\", entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_emotions = ['anger', 'fear', 'joy', 'sadness', 'disgust', 'surprise']\n",
    "\n",
    "ja_basic_emotion_concepts = {\n",
    "    emotion: list(words) for emotion, words in japanese_nrc_emotion_dict.items() if emotion in basic_emotions\n",
    "}\n",
    "en_basic_emotion_concepts = {\n",
    "    emotion: list(words) for emotion, words in english_nrc_emotion_dict.items() if emotion in basic_emotions\n",
    "}\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "# check if the fastText embeddings are downloaded\n",
    "import os\n",
    "\n",
    "if not os.path.isfile('cc.ja.300.bin'):\n",
    "    fasttext.util.download_model('ja', if_exists='ignore') \n",
    "if not os.path.isfile('cc.en.300.bin'):\n",
    "    fasttext.util.download_model('en', if_exists='ignore')\n",
    "\n",
    "ja_embeddings = fasttext.load_model('cc.ja.300.bin')\n",
    "en_embeddings = fasttext.load_model('cc.en.300.bin')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function: english emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear': 0.41364282, 'sadness': 0.42352962, 'anger': 0.42670834, 'surprise': 0.48255157, 'disgust': 0.39483708, 'joy': 0.44914463}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.downloader as api\n",
    "\n",
    "# load pre-trained fastText embeddings\n",
    "def load_fasttext_embeddings(model_name):\n",
    "    model = api.load(model_name)\n",
    "    # Get the mean vector for the list of words\n",
    "    # mean_vector = np.mean([model1[word] for word in wordlist if word in word_vectors], axis=0)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load pre-trained GloVe embeddings\n",
    "def load_glove_embeddings(embeddings_file):\n",
    "    embeddings = {}\n",
    "    with open(embeddings_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Vectorize the dictionary of moral and emotional concepts\n",
    "def vectorize_concepts(concepts, embeddings):\n",
    "    concept_vectors = {}\n",
    "    for concept, words in concepts.items():\n",
    "        vectors = [embeddings[word] for word in words if word in embeddings]\n",
    "        concept_vectors[concept] = np.mean(vectors, axis=0)\n",
    "    return concept_vectors\n",
    "\n",
    "# Vectorize the input text\n",
    "def vectorize_text(text, embeddings):\n",
    "    tokens = word_tokenize(text)\n",
    "    vectors = [embeddings[token] for token in tokens if token in embeddings]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Calculate cosine similarity between input text and moral and emotional concepts\n",
    "def calculate_similarities(text_vector, concept_vectors):\n",
    "    similarities = {}\n",
    "    for concept, vector in concept_vectors.items():\n",
    "        similarities[concept] = cosine_similarity(text_vector.reshape(1, -1), vector.reshape(1, -1))[0][0]\n",
    "    return similarities\n",
    "\n",
    "# Example usage:\n",
    "# glove_embeddings_file = 'glove.6B.300d.txt'\n",
    "# glove_embeddings = load_glove_embeddings(glove_embeddings_file)\n",
    "# en_embeddings = load_fasttext_embeddings(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "# Define your moral and emotional concepts dictionary here\n",
    "concept_vectors = vectorize_concepts(en_basic_emotion_concepts, en_embeddings)\n",
    "\n",
    "text = \"This is an example text to analyze moral and emotional content.\"\n",
    "text_vector = vectorize_text(text, en_embeddings)\n",
    "\n",
    "similarities = calculate_similarities(text_vector, concept_vectors)\n",
    "print(similarities)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jp emotions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT IN USE: Tokenize the input text using Janome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear': 0.28294072, 'sadness': 0.28086483, 'anger': 0.28085762, 'surprise': 0.30233887, 'disgust': 0.28768104, 'joy': 0.27653188}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# Load pre-trained FastText embeddings\n",
    "def load_fasttext_embeddings(embeddings_file):\n",
    "    embeddings = {}\n",
    "    with open(embeddings_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Vectorize the dictionary of moral and emotional concepts\n",
    "def vectorize_concepts(concepts, embeddings):\n",
    "    concept_vectors = {}\n",
    "    for concept, words in concepts.items():\n",
    "        vectors = [embeddings[word] for word in words if word in embeddings]\n",
    "        concept_vectors[concept] = np.mean(vectors, axis=0)\n",
    "    return concept_vectors\n",
    "\n",
    "# Tokenize the input text using Janome\n",
    "def tokenize_japanese_text(text):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokens = tokenizer.tokenize(text, wakati=True)\n",
    "    return tokens\n",
    "\n",
    "# Vectorize the input text\n",
    "def vectorize_text(tokens, embeddings):\n",
    "    vectors = [embeddings[token] for token in tokens if token in embeddings]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Calculate cosine similarity between input text and moral and emotional concepts\n",
    "def calculate_similarities(text_vector, concept_vectors):\n",
    "    similarities = {}\n",
    "    for concept, vector in concept_vectors.items():\n",
    "        similarities[concept] = cosine_similarity(text_vector.reshape(1, -1), vector.reshape(1, -1))[0][0]\n",
    "    return similarities\n",
    "\n",
    "# ENTROPY\n",
    "def emotion_entropy(post_emotions, threshold=0.5):\n",
    "    binary_emotions = [1 if emotion >= threshold else 0 for emotion in post_emotions]\n",
    "    probabilities = [emotion_count / len(post_emotions) for emotion_count in binary_emotions]\n",
    "    \n",
    "    entropy = -np.sum([p * np.log2(p) if p > 0 else 0 for p in probabilities])\n",
    "    return entropy\n",
    "# Define your moral and emotional concepts dictionary here\n",
    "concepts = en_basic_emotion_concepts\n",
    "\n",
    "concept_vectors = vectorize_concepts(concepts, en_embeddings)\n",
    "\n",
    "text = \"His success is wonderful, but at the same time, I feel a bit jealous.\"\n",
    "text_vector = vectorize_text(text, en_embeddings)\n",
    "\n",
    "similarities = calculate_similarities(text_vector, concept_vectors)\n",
    "\n",
    "entropy = emotion_entropy(list(similarities.values()))\n",
    "print(similarities)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.6377529, 'disgust': 0.611441, 'fear': 0.62469923, 'joy': 0.6755974, 'sadness': 0.6264248, 'surprise': 0.67802525}\n",
      "2.584962500721156\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "def tokenize_japanese_text_mecab(text):\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    return mecab.parse(text).strip().split()\n",
    "\n",
    "def vectorize_jp_concepts(concepts, embeddings):\n",
    "    concept_vectors = {}\n",
    "    for concept, words in concepts.items():\n",
    "        vectors = [ja_embeddings.get_word_vector(word) for word in words]\n",
    "        concept_vectors[concept] = np.mean(vectors, axis=0)\n",
    "    return concept_vectors\n",
    "\n",
    "# Vectorize the input text\n",
    "def vectorize_jp_text(tokens, embeddings):\n",
    "    vectors =[ja_embeddings.get_word_vector(token) for token in tokens]\n",
    "    return np.mean(vectors, axis=0)\n",
    "# Example usage:\n",
    "# fasttext_embeddings_file = 'cc.ja.300.vec'\n",
    "# fasttext_embeddings = load_fasttext_embeddings(fasttext_embeddings_file)\n",
    "\n",
    "# Define your moral and emotional concepts dictionary here\n",
    "concept_vectors = vectorize_jp_concepts(ja_basic_emotion_concepts, ja_embeddings)\n",
    "\n",
    "# concept_vectors = vectorize_concepts(concepts, ja_embeddings)\n",
    "\n",
    "text = \"これは道徳的および感情的なコンテンツを分析するための例文です\"\n",
    "tokens = tokenize_japanese_text_mecab(text)\n",
    "text_vector = vectorize_jp_text(tokens, ja_embeddings)\n",
    "\n",
    "similarities = calculate_similarities(text_vector, concept_vectors)\n",
    "\n",
    "entropy = emotion_entropy(list(similarities.values()))\n",
    "print(similarities)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so happy to see you, but I'm sad that you have to leave soon. {'fear': 0.37510133, 'sadness': 0.41060042, 'anger': 0.3957128, 'surprise': 0.45528015, 'disgust': 0.38073587, 'joy': 0.43462107} 0\n",
      "I'm anxious about the exam, but I'm also excited about the challenge. {'fear': 0.3561712, 'sadness': 0.38363206, 'anger': 0.37038356, 'surprise': 0.41533506, 'disgust': 0.35978395, 'joy': 0.3962078} 0\n",
      "I'm surprised and disappointed by the news. {'fear': 0.37021977, 'sadness': 0.3916921, 'anger': 0.38696092, 'surprise': 0.420673, 'disgust': 0.36965284, 'joy': 0.38753802} 0\n",
      "彼の成功は素晴らしいけれども、同時に少し嫉妬心がある {'anger': 0.65449595, 'disgust': 0.6265899, 'fear': 0.6435342, 'joy': 0.7127478, 'sadness': 0.65797377, 'surprise': 0.7134285} 2.584962500721156\n",
      "仕事が終わったので安心だが、週末のパーティには緊張している {'anger': 0.5855845, 'disgust': 0.5570482, 'fear': 0.57905364, 'joy': 0.647285, 'sadness': 0.59128726, 'surprise': 0.6525617} 2.584962500721156\n",
      "彼女の発表には驚いたが、ちょっと怒りも感じた {'anger': 0.61370766, 'disgust': 0.5839083, 'fear': 0.59912133, 'joy': 0.64974535, 'sadness': 0.6166384, 'surprise': 0.678076} 2.584962500721156\n"
     ]
    }
   ],
   "source": [
    "en_mixed_emotion_sentences = [\n",
    "    \"I'm so happy to see you, but I'm sad that you have to leave soon.\",\n",
    "    \n",
    "    \"I'm anxious about the exam, but I'm also excited about the challenge.\",\n",
    "    \n",
    "    \"I'm surprised and disappointed by the news.\",\n",
    "]\n",
    "\n",
    "ja_mixed_emotion_sentences = [\n",
    "    \"彼の成功は素晴らしいけれども、同時に少し嫉妬心がある\",\n",
    "    \"仕事が終わったので安心だが、週末のパーティには緊張している\",\n",
    "    \"彼女の発表には驚いたが、ちょっと怒りも感じた\",\n",
    "]\n",
    "\n",
    "def calculate_mixed_emotion_entropy(sentence, embeddings, language='en'):\n",
    "    \n",
    "    if language == 'ja':\n",
    "        concept_vectors = vectorize_jp_concepts(ja_basic_emotion_concepts, embeddings)\n",
    "        tokens = tokenize_japanese_text_mecab(sentence)\n",
    "        text_vector = vectorize_jp_text(tokens, embeddings)\n",
    "    else:\n",
    "        concept_vectors = vectorize_concepts(en_basic_emotion_concepts, embeddings)\n",
    "        text_vector = vectorize_text(sentence, embeddings)\n",
    "    similarities = calculate_similarities(text_vector, concept_vectors)\n",
    "    entropy = emotion_entropy(list(similarities.values()))\n",
    "    return similarities, entropy\n",
    "\n",
    "for sentence in en_mixed_emotion_sentences:\n",
    "    similarities, entropy = calculate_mixed_emotion_entropy(sentence, en_embeddings)\n",
    "    print(sentence, similarities, entropy)\n",
    "\n",
    "for sentence in ja_mixed_emotion_sentences:\n",
    "    similarities, entropy = calculate_mixed_emotion_entropy(sentence, ja_embeddings, language='ja')\n",
    "    print(sentence, similarities, entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm thrilled to have received the promotion, but I'm also nervous about the new responsibilities that come with it. {'fear': 0.401712, 'sadness': 0.42628855, 'anger': 0.41740072, 'surprise': 0.47821116, 'disgust': 0.39795023, 'joy': 0.45706573} 0\n",
      "I was relieved that the medical test came back negative, but I'm still worried about my persistent symptoms. {'fear': 0.43635708, 'sadness': 0.46855152, 'anger': 0.44494754, 'surprise': 0.49110746, 'disgust': 0.43099713, 'joy': 0.45792305} 0\n",
      "I'm excited to start this new chapter in my life, but I'm sad about leaving my friends and family behind. {'fear': 0.41011935, 'sadness': 0.44670117, 'anger': 0.42168635, 'surprise': 0.48029295, 'disgust': 0.40653467, 'joy': 0.47900423} 0\n",
      "It's heartbreaking to say goodbye to my colleagues, but I am eager to explore the new job opportunity. {'fear': 0.39935225, 'sadness': 0.42127663, 'anger': 0.41590923, 'surprise': 0.48764572, 'disgust': 0.3840256, 'joy': 0.4741584} 0\n",
      "I'm proud of my children for becoming independent, but I'm also feeling a little lonely now that they've moved out. {'fear': 0.4206523, 'sadness': 0.4545647, 'anger': 0.43409204, 'surprise': 0.4832191, 'disgust': 0.42299443, 'joy': 0.4753496} 0\n",
      "I feel joyous for my friend's wedding, but at the same time, I'm feeling a bit envious. {'fear': 0.41491586, 'sadness': 0.4469679, 'anger': 0.43043375, 'surprise': 0.4935189, 'disgust': 0.41296646, 'joy': 0.48345375} 0\n",
      "昇進してとてもうれしいですが、新しい責任にも少し緊張しています。 {'anger': 0.52005297, 'disgust': 0.48876804, 'fear': 0.5063507, 'joy': 0.5754167, 'sadness': 0.52527916, 'surprise': 0.58148366} 2.15413541726763\n",
      "医療検査が陰性でほっとしていますが、持続的な症状についてはまだ心配しています。 {'anger': 0.5490009, 'disgust': 0.53207624, 'fear': 0.5487734, 'joy': 0.5841475, 'sadness': 0.56324166, 'surprise': 0.60204244} 2.584962500721156\n",
      "新しい生活の章を開始するのが楽しみですが、友人や家族と離れることは悲しいです。 {'anger': 0.6087128, 'disgust': 0.575875, 'fear': 0.6005447, 'joy': 0.6765133, 'sadness': 0.6104679, 'surprise': 0.6691775} 2.584962500721156\n",
      "同僚に別れを告げるのは心が痛むけれど、新たな仕事の機会を探求することには前向きです。 {'anger': 0.650279, 'disgust': 0.61667764, 'fear': 0.64070165, 'joy': 0.7179837, 'sadness': 0.65337014, 'surprise': 0.71122086} 2.584962500721156\n",
      "子どもたちが自立してくれて誇らしいですが、彼らが引っ越してからは少し寂しい気もします。 {'anger': 0.52984273, 'disgust': 0.5031283, 'fear': 0.5180981, 'joy': 0.59123564, 'sadness': 0.53556526, 'surprise': 0.58991086} 2.584962500721156\n",
      "友人の結婚に喜んでいる一方で、少し羨ましい気もします。 {'anger': 0.5484063, 'disgust': 0.52543926, 'fear': 0.5327827, 'joy': 0.61970735, 'sadness': 0.5560203, 'surprise': 0.6119412} 2.584962500721156\n"
     ]
    }
   ],
   "source": [
    "mixed_emotion_sentences = {\n",
    "    \"sentence1\": \"I'm thrilled to have received the promotion, but I'm also nervous about the new responsibilities that come with it.\",\n",
    "    \"sentence2\": \"I was relieved that the medical test came back negative, but I'm still worried about my persistent symptoms.\",\n",
    "    \"sentence3\": \"I'm excited to start this new chapter in my life, but I'm sad about leaving my friends and family behind.\",\n",
    "    \"sentence4\": \"It's heartbreaking to say goodbye to my colleagues, but I am eager to explore the new job opportunity.\",\n",
    "    \"sentence5\": \"I'm proud of my children for becoming independent, but I'm also feeling a little lonely now that they've moved out.\",\n",
    "    \"sentence6\": \"I feel joyous for my friend's wedding, but at the same time, I'm feeling a bit envious.\",\n",
    "}\n",
    "en_mixed_emotion_sentences = list(mixed_emotion_sentences.values())\n",
    "\n",
    "ja_mixed_emotion_sentences= [\n",
    "    \"昇進してとてもうれしいですが、新しい責任にも少し緊張しています。\",\n",
    "    \"医療検査が陰性でほっとしていますが、持続的な症状についてはまだ心配しています。\",\n",
    "    \"新しい生活の章を開始するのが楽しみですが、友人や家族と離れることは悲しいです。\",\n",
    "    \"同僚に別れを告げるのは心が痛むけれど、新たな仕事の機会を探求することには前向きです。\",\n",
    "    \"子どもたちが自立してくれて誇らしいですが、彼らが引っ越してからは少し寂しい気もします。\",\n",
    "    \"友人の結婚に喜んでいる一方で、少し羨ましい気もします。\",\n",
    "]\n",
    "\n",
    "\n",
    "for sentence in en_mixed_emotion_sentences:\n",
    "    similarities, entropy = calculate_mixed_emotion_entropy(sentence, en_embeddings)\n",
    "    print(sentence, similarities, entropy)\n",
    "\n",
    "for sentence in ja_mixed_emotion_sentences:\n",
    "    similarities, entropy = calculate_mixed_emotion_entropy(sentence, ja_embeddings, language='ja')\n",
    "    print(sentence, similarities, entropy)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# caculate tweets entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 25630/1471856 [1:21:32<70:01:16,  5.74it/s] "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "entropies = []\n",
    "angers = []\n",
    "fears = []\n",
    "joys = []\n",
    "sadnesses = []\n",
    "disgusts = []\n",
    "surprises = []\n",
    "\n",
    "for t in tqdm(usdf['text']):\n",
    "    text_vector = vectorize_text(t, en_embeddings)\n",
    "\n",
    "    similarities = calculate_similarities(text_vector, concept_vectors)\n",
    "    # similarities, entroppy = calculate_mixed_emotion_entropy(t, en_embeddings)\n",
    "    # entropies.append(entropy)\n",
    "    angers.append(similarities['anger'])\n",
    "    fears.append(similarities['fear'])\n",
    "    joys.append(similarities['joy'])\n",
    "    sadnesses.append(similarities['sadness'])\n",
    "    disgusts.append(similarities['disgust'])\n",
    "    surprises.append(similarities['surprise'])\n",
    "\n",
    "# usdf['entropy'] = entropies\n",
    "usdf['anger'] = angers\n",
    "usdf['fear'] = fears\n",
    "usdf['joy'] = joys\n",
    "usdf['sadness'] = sadnesses\n",
    "usdf['disgust'] = disgusts\n",
    "usdf['surprise'] = surprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angers = []\n",
    "fears = []\n",
    "joys = []\n",
    "sadnesses = []\n",
    "disgusts = []\n",
    "surprises = []\n",
    "\n",
    "for t in tqdm(jadf['text']):\n",
    "    tokens = tokenize_japanese_text_mecab(t)\n",
    "    text_vector = vectorize_jp_text(tokens, ja_embeddings)\n",
    "    similarities = calculate_similarities(text_vector, concept_vectors)\n",
    "    # similarities, entroppy = calculate_mixed_emotion_entropy(t, en_embeddings)\n",
    "    # entropies.append(entropy)\n",
    "    angers.append(similarities['anger'])\n",
    "    fears.append(similarities['fear'])\n",
    "    joys.append(similarities['joy'])\n",
    "    sadnesses.append(similarities['sadness'])\n",
    "    disgusts.append(similarities['disgust'])\n",
    "    surprises.append(similarities['surprise'])\n",
    "\n",
    "jadf['anger'] = angers\n",
    "jadf['fear'] = fears\n",
    "jadf['joy'] = joys\n",
    "jadf['sadness'] = sadnesses\n",
    "jadf['disgust'] = disgusts\n",
    "jadf['surprise'] = surprises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "usdf.to_csv(os.path.join(preprocessed_folder_path,\"us_entropy.csv\") index=False)\n",
    "jpdf.to_csv(os.path.join(preprocessed_folder_path,\"jp_entropy.csv\") , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the entropy of the two languages\n",
    "print(usdf['entropy'].mean())\n",
    "print(jpdf['entropy'].mean())\n",
    "\n",
    "# test which is higher\n",
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(usdf['entropy'], jpdf['entropy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f669a5dd70341fe1cf9fa92e7b3b20791cc959f37db4cdb468169999145ea5f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
